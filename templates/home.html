<head>
    <link rel="stylesheet" href="{{ url_for('static',filename='main.css') }}">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
</head>

<!-- <img class='menu' src="/static/menu.png" alt="" srcset=""> -->
<!-- 
<div class="men">
    <svg class='logo-home' xmlns="http://www.w3.org/2000/svg" viewBox="0 0 484.131 175">
        <g id="Group_11" data-name="Group 11" transform="translate(-1205 -265)">
            <g id="Group_7" data-name="Group 7" transform="translate(1205 265)">
                <g id="Group_6" data-name="Group 6">
                    <text id="SiKiZa" transform="translate(0 142)" font-size="132" font-family="SegoeUI-Bold, Segoe UI"
                        font-weight="700">
                        <tspan x="0" y="0">SiKiZa</tspan>
                    </text>
                    <g id="Group_4" data-name="Group 4" transform="translate(392.816 60.464)">
                        <ellipse id="Ellipse_1" data-name="Ellipse 1" cx="21" cy="22" rx="21" ry="22"
                            transform="translate(0.184 42.536)" />
                        <rect id="Rectangle_4" data-name="Rectangle 4" width="10.667" height="18.496" rx="5.333"
                            transform="matrix(0.799, -0.602, 0.602, 0.799, 34.146, 42.299)" />
                        <rect id="Rectangle_5" data-name="Rectangle 5" width="10.667" height="37.141" rx="5.333"
                            transform="matrix(0.799, -0.602, 0.602, 0.799, 41.581, 25.758)" />
                        <rect id="Rectangle_7" data-name="Rectangle 7" width="10.667" height="58.666" rx="5.333"
                            transform="matrix(0.799, -0.602, 0.602, 0.799, 47.49, 6.419)" />
                    </g>
                </g>
            </g>
        </g>
    </svg> -->


</div>





<div class="pane-3">

<img class='menu' id='menu' src="/static/menu2.png" alt="" srcset="">

    <div class="menulist">
        <ul>
            <li><a href="#">Languages</a></li>
            <li><a href="#">Who can use</a></li>
        </ul>
    </div>
    <div id="label-container"></div>
</div>


<div class="notice">Click on the video button to start</div>



<div id="webcam-container">

<div class="say">
    <center>
        <img class='ii-img' src="/static/ii.png" alt="">
    </center>
    <div class="iisay">
        make an action to your computer
    </div>
</div>
    
<div id="play">
    <i id='playicon' class="material-icons">videocam</i>
</div>
<div id="pause">
    <i id='pause_arrow' class="material-icons">stop_arrow</i>
</div>

</div>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@0.8/dist/teachablemachine-image.min.js"></script>
<script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/image

    // the link to your model provided by Teachable Machine export panel
    const URL = "https://teachablemachine.withgoogle.com/models/Rqje8FOCj/";

    let model, webcam, labelContainer, maxPredictions;
    const stopbutt = document.getElementById('stop')

    const play = document.getElementById('play')
    let pause = document.getElementById('pause')

    const container = document.getElementById('webcam-container')
    let ispause = false

    const pane_3 = document.getElementsByClassName('pane-3')
    const notice = document.getElementsByClassName('notice')

    const menulist = document.getElementsByClassName('menulist')
    const menu = document.getElementById('menu')

    const say = document.getElementsByClassName('say')


    

    // Load the image model and setup the webcam

    pause.addEventListener('click', async () => {
        window.location.href = '/home'
    })

   
    menu.addEventListener('click',()=>{
         menulist[0].style.marginLeft = 0
         menulist[0].style.transition = 0.5 +'s'
    })




    play.addEventListener('click', async () => {


        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        pane_3[0].style.marginLeft = 0
        pane_3[0].style.transition = 0.5 +'s'
        container.style.left = 50 + '%'
        container.style.transition = 0.5 +'s'
        notice[0].style.display = 'none'
        say[0].style.display = 'none'
        say[0].style.transition = 0.5 + 's'


        container.style.borderRadius = 10 + 'px'
        container.style.width = 320 + 'px'
        container.style.transition = 0.5 + 's'




        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(390, 390, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);




        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }

        container.addEventListener('mouseover', () => {
            pause.style.display = 'block'
        })
        container.addEventListener('mouseout', () => {
            pause.style.display = 'none'
        })
        pause.addEventListener('mouseover', () => {
            pause.style.display = 'block'
        })

        play.style.display = 'none'

    })






    async function init() {

    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    // run the webcam image through the image model
    async function predict() {
        // predict can take in an image, video or canvas html element
        const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {

            if (prediction[i].probability.toFixed(2) > 0.8) {

                const classPrediction = prediction[i].className;
                labelContainer.childNodes[i].innerHTML = classPrediction;

            } else {

                // const classPrediction =null;
                const classPrediction = prediction[i].className;
                labelContainer.childNodes[i].innerHTML = '';

            }

        }
    }
</script>